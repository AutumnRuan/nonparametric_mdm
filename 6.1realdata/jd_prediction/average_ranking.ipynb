{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "offertimes_lst = [20,30,40,50,60]\n",
    "\n",
    "all_mdm_dist = []\n",
    "all_mdm_relative_regret = []\n",
    "for i in range(len(offertimes_lst)):\n",
    "    mdm_results = pd.read_csv('prediction/etp_mdm/revenue_prediction/details1/'+str(offertimes_lst[i])+'.csv')\n",
    "    mdm_lb_dist = mdm_results['mdm_lb_dist']\n",
    "    mdm_lb_dist = mdm_lb_dist.tolist()\n",
    "    mdm_lb_best_rev_diff = mdm_results['mdm_lb_best_rev_diff']\n",
    "    mdm_lb_best_rev_diff = mdm_lb_best_rev_diff.tolist()\n",
    "    all_mdm_dist.append(mdm_lb_dist)\n",
    "    all_mdm_relative_regret.append(mdm_lb_best_rev_diff)\n",
    "    \n",
    "all_rum_dist = []\n",
    "all_rum_relative_regret = []\n",
    "for i in range(len(offertimes_lst)):\n",
    "    rum_results = pd.read_csv('prediction/rum/revenue_prediction/details1/'+str(offertimes_lst[i])+'.csv')\n",
    "    rum_lb_dist = rum_results['rum_lb_dist']\n",
    "    rum_lb_dist = rum_lb_dist.tolist()\n",
    "    rum_lb_best_rev_diff = rum_results['rum_lb_best_rev_diff']\n",
    "    rum_lb_best_rev_diff = rum_lb_best_rev_diff.tolist()\n",
    "    all_rum_dist.append(rum_lb_dist)\n",
    "    all_rum_relative_regret.append(rum_lb_best_rev_diff)\n",
    "\n",
    "\n",
    "all_mnl_dist = []\n",
    "all_mnl_relative_regret = []\n",
    "for i in range(len(offertimes_lst)):\n",
    "    mnl_results = pd.read_csv('prediction/mnl/revenue_prediction/details1/'+str(offertimes_lst[i])+'.csv')\n",
    "    mnl_dist = mnl_results['mnl_dist']\n",
    "    mnl_dist = mnl_dist.tolist()\n",
    "    mnl_best_rev_diff = mnl_results['mnl_best_rev_diff']\n",
    "    mnl_best_rev_diff = mnl_best_rev_diff.tolist()\n",
    "    all_mnl_dist.append(mnl_dist)\n",
    "    all_mnl_relative_regret.append(mnl_best_rev_diff)\n",
    "\n",
    "all_mccm_dist = []\n",
    "all_mccm_relative_regret = []\n",
    "for i in range(len(offertimes_lst)):\n",
    "    mccm_results = pd.read_csv('prediction/mccm/revenue_prediction/details1/'+str(offertimes_lst[i])+'.csv')\n",
    "    mccm_dist = mccm_results['mccm_dist']\n",
    "    mccm_dist = mccm_dist.tolist()\n",
    "    mccm_best_rev_diff = mccm_results['mccm_best_rev_diff']\n",
    "    mccm_best_rev_diff = mccm_best_rev_diff.tolist()\n",
    "    all_mccm_dist.append(mccm_dist)\n",
    "    all_mccm_relative_regret.append(mccm_best_rev_diff)\n",
    "    \n",
    "all_lcmnl_dist = []\n",
    "all_lcmnl_relative_regret = []\n",
    "for i in range(len(offertimes_lst)):\n",
    "    lcmnl_results = pd.read_csv('prediction/lcmnl/revenue_prediction/details1/'+str(offertimes_lst[i])+'.csv')\n",
    "    lcmnl_dist = lcmnl_results['lcmnl_dist']\n",
    "    lcmnl_dist = lcmnl_dist.tolist()\n",
    "    lcmnl_best_rev_diff = lcmnl_results['lcmnl_best_rev_diff']\n",
    "    lcmnl_best_rev_diff = lcmnl_best_rev_diff.tolist()\n",
    "    all_lcmnl_dist.append(lcmnl_dist)\n",
    "    all_lcmnl_relative_regret.append(lcmnl_best_rev_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_w_distance(distances):\n",
    "    # Combine distances with their original indices\n",
    "    indexed_distances = list(enumerate(distances))\n",
    "\n",
    "    # Sort based on distances\n",
    "    sorted_distances = sorted(indexed_distances, key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the ranking list\n",
    "    ranks = [0] * len(distances)\n",
    "\n",
    "    # Assign ranks\n",
    "    rank = 1\n",
    "    for i in range(len(sorted_distances)):\n",
    "        if i > 0 and sorted_distances[i][1] != sorted_distances[i-1][1]:\n",
    "            rank += 1\n",
    "        ranks[sorted_distances[i][0]] = rank\n",
    "\n",
    "    return ranks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_w_models(distances):\n",
    "    # Sort the distances and assign ranks\n",
    "    sorted_distances = sorted(distances)\n",
    "    rank_list = []\n",
    "    rank = 1\n",
    "    previous_distance = sorted_distances[0]\n",
    "\n",
    "    # Assign ranks\n",
    "    for i, distance in enumerate(sorted_distances):\n",
    "        if distance > previous_distance:\n",
    "            rank = i + 1\n",
    "        rank_list.append(rank)\n",
    "        previous_distance = distance\n",
    "\n",
    "    # Reverse mapping the rank list to match the original distances order\n",
    "    final_rankings = [rank_list[sorted_distances.index(d)] for d in distances]\n",
    "\n",
    "    return final_rankings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_ranking_w_tie(distances):\n",
    "    # Combine distances with their original indices\n",
    "    indexed_distances = list(enumerate(distances))\n",
    "\n",
    "    # Sort based on distances\n",
    "    sorted_distances = sorted(indexed_distances, key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the ranking list\n",
    "    ranks = [0] * len(distances)\n",
    "\n",
    "    # Assign ranks with averaging for ties\n",
    "    i = 0\n",
    "    while i < len(sorted_distances):\n",
    "        start = i\n",
    "        current_distance = sorted_distances[i][1]\n",
    "        \n",
    "        # Move forward to find the end of the tie\n",
    "        while i < len(sorted_distances) - 1 and sorted_distances[i + 1][1] == current_distance:\n",
    "            i += 1\n",
    "        \n",
    "        # Calculate the average rank for ties\n",
    "        average_rank = (start + 1 + i + 1) / 2.0\n",
    "        \n",
    "        # Assign the average rank to all tied elements\n",
    "        for j in range(start, i + 1):\n",
    "            ranks[sorted_distances[j][0]] = average_rank\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the average ranking of models\n",
    "all_avg_ranking_dist = []\n",
    "all_avg_ranking_regret = []\n",
    "\n",
    "for i in range(len(offertimes_lst)):\n",
    "    \n",
    "    avg_dist_ranking_lst = []\n",
    "    avg_reg_ranking_lst = []\n",
    "    \n",
    "    for j in range(50):\n",
    "        curr_distances = [all_mdm_dist[i][j],all_rum_dist[i][j],all_mnl_dist[i][j],all_mccm_dist[i][j],all_lcmnl_dist[i][j]]\n",
    "        curr_dist_ranking = avg_ranking_w_tie(curr_distances)\n",
    "        avg_dist_ranking_lst.append(curr_dist_ranking)\n",
    "        \n",
    "        curr_relative_regret = [all_mdm_relative_regret[i][j],all_rum_relative_regret[i][j],all_mnl_relative_regret[i][j],all_mccm_relative_regret[i][j],all_lcmnl_relative_regret[i][j]]\n",
    "        curr_relative_regret_ranking = avg_ranking_w_tie(curr_relative_regret)\n",
    "        avg_reg_ranking_lst.append(curr_relative_regret_ranking)\n",
    "    \n",
    "    all_avg_ranking_dist.append(avg_dist_ranking_lst)\n",
    "    all_avg_ranking_regret.append(avg_reg_ranking_lst)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.5, 2.5, 4.5, 4.5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_avg_ranking_dist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_mdm_dist_rank = []\n",
    "all_rum_dist_rank = []\n",
    "all_mnl_dist_rank = []\n",
    "all_mccm_dist_rank = []\n",
    "all_lcmnl_dist_rank = []\n",
    "\n",
    "\n",
    "all_mdm_regret_rank = []\n",
    "all_rum_regret_rank = []\n",
    "all_mnl_regret_rank = []\n",
    "all_mccm_regret_rank = []\n",
    "all_lcmnl_regret_rank = []\n",
    "\n",
    "for i in range(len(offertimes_lst)):\n",
    "    mdm_dist_rank_lst = []\n",
    "    rum_dist_rank_lst = []\n",
    "    mnl_dist_rank_lst = []\n",
    "    mccm_dist_rank_lst = []\n",
    "    lcmnl_dist_rank_lst = []\n",
    "\n",
    "\n",
    "    mdm_regret_rank_lst = []\n",
    "    rum_regret_rank_lst = []\n",
    "    mnl_regret_rank_lst = []\n",
    "    mccm_regret_rank_lst = []\n",
    "    lcmnl_regret_rank_lst = []\n",
    "    \n",
    "    for j in range(50):\n",
    "        mdm_dist_rank_lst.append(all_avg_ranking_dist[i][j][0])\n",
    "        rum_dist_rank_lst.append(all_avg_ranking_dist[i][j][1])\n",
    "        mnl_dist_rank_lst.append(all_avg_ranking_dist[i][j][2])\n",
    "        mccm_dist_rank_lst.append(all_avg_ranking_dist[i][j][3])\n",
    "        lcmnl_dist_rank_lst.append(all_avg_ranking_dist[i][j][4])\n",
    "        \n",
    "        mdm_regret_rank_lst.append(all_avg_ranking_regret[i][j][0])\n",
    "        rum_regret_rank_lst.append(all_avg_ranking_regret[i][j][1])\n",
    "        mnl_regret_rank_lst.append(all_avg_ranking_regret[i][j][2])\n",
    "        mccm_regret_rank_lst.append(all_avg_ranking_regret[i][j][3])\n",
    "        lcmnl_regret_rank_lst.append(all_avg_ranking_regret[i][j][4])\n",
    "    \n",
    "    all_mdm_dist_rank.append(mdm_dist_rank_lst)\n",
    "    all_rum_dist_rank.append(rum_dist_rank_lst)\n",
    "    all_mnl_dist_rank.append(mnl_dist_rank_lst)\n",
    "    all_mccm_dist_rank.append(mccm_dist_rank_lst)\n",
    "    all_lcmnl_dist_rank.append(lcmnl_dist_rank_lst)\n",
    "    \n",
    "    all_mdm_regret_rank.append(mdm_regret_rank_lst)\n",
    "    all_rum_regret_rank.append(rum_regret_rank_lst)\n",
    "    all_mnl_regret_rank.append(mnl_regret_rank_lst)\n",
    "    all_mccm_regret_rank.append(mccm_regret_rank_lst)\n",
    "    all_lcmnl_regret_rank.append(lcmnl_regret_rank_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(data):\n",
    "    unique_values, counts = np.unique(data, return_counts=True)\n",
    "    distribution = counts / len(data)\n",
    "    return unique_values, distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertime</th>\n",
       "      <th>mdm</th>\n",
       "      <th>rum</th>\n",
       "      <th>mnl</th>\n",
       "      <th>mccm</th>\n",
       "      <th>lcmnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertime   mdm   rum   mnl  mccm  lcmnl\n",
       "0         20  2.65  3.14  3.70  2.72   2.79\n",
       "1         30  3.00  3.48  3.36  2.81   2.35\n",
       "2         40  2.93  3.28  3.34  3.00   2.45\n",
       "3         50  3.02  3.25  3.16  2.71   2.86\n",
       "4         60  2.96  2.91  3.06  3.01   3.06"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the distribution of ranking of compared models\n",
    "\n",
    "\n",
    "mdm_dist_rank_realizations = []\n",
    "mdm_dist_rank_distributions = []\n",
    "\n",
    "rum_dist_rank_realizations = []\n",
    "rum_dist_rank_distributions = []\n",
    "\n",
    "mnl_dist_rank_realizations = []\n",
    "mnl_dist_rank_distributions = []\n",
    "\n",
    "mccm_dist_rank_realizations = []\n",
    "mccm_dist_rank_distributions = []\n",
    "\n",
    "lcmnl_dist_rank_realizations = []\n",
    "lcmnl_dist_rank_distributions = []\n",
    "\n",
    "mdm_dist_rank_expectations = []\n",
    "rum_dist_rank_expectations = []\n",
    "mnl_dist_rank_expectations = []\n",
    "mccm_dist_rank_expectations = []\n",
    "lcmnl_dist_rank_expectations = []\n",
    "\n",
    "for i in range(len(offertimes_lst)):\n",
    "    mdm_realization, mdm_distribution = get_distribution(all_mdm_dist_rank[i])\n",
    "    rum_realization, rum_distribution = get_distribution(all_rum_dist_rank[i])\n",
    "    mnl_realization, mnl_distribution = get_distribution(all_mnl_dist_rank[i])\n",
    "    mccm_realization, mccm_distribution = get_distribution(all_mccm_dist_rank[i])\n",
    "    lcmnl_realization, lcmnl_distribution = get_distribution(all_lcmnl_dist_rank[i])\n",
    "    \n",
    "    mdm_df = pd.DataFrame({'realizations':mdm_realization,'distribution':mdm_distribution})\n",
    "    mdm_df.to_csv('avg_ranking/dist/'+str(offertimes_lst[i])+'/mdm.csv')\n",
    "    \n",
    "    rum_df = pd.DataFrame({'realizations':rum_realization,'distribution':rum_distribution})\n",
    "    rum_df.to_csv('avg_ranking/dist/'+str(offertimes_lst[i])+'/rum.csv')\n",
    "    \n",
    "    mnl_df = pd.DataFrame({'realizations':mnl_realization,'distribution':mnl_distribution})\n",
    "    mnl_df.to_csv('avg_ranking/dist/'+str(offertimes_lst[i])+'/mnl.csv')\n",
    "    \n",
    "    mccm_df = pd.DataFrame({'realizations':mccm_realization,'distribution':mccm_distribution})\n",
    "    mccm_df.to_csv('avg_ranking/dist/'+str(offertimes_lst[i])+'/mccm.csv')\n",
    "    \n",
    "    lcmnl_df = pd.DataFrame({'realizations':lcmnl_realization,'distribution':lcmnl_distribution})\n",
    "    lcmnl_df.to_csv('avg_ranking/dist/'+str(offertimes_lst[i])+'/lcmnl.csv')\n",
    "    \n",
    "    mdm_dist_rank_expectations.append(np.sum(mdm_realization * mdm_distribution))\n",
    "    rum_dist_rank_expectations.append(np.sum(rum_realization * rum_distribution))\n",
    "    mnl_dist_rank_expectations.append(np.sum(mnl_realization * mnl_distribution))\n",
    "    mccm_dist_rank_expectations.append(np.sum(mccm_realization * mccm_distribution))\n",
    "    lcmnl_dist_rank_expectations.append(np.sum(lcmnl_realization * lcmnl_distribution))\n",
    "\n",
    "expected_dist_rank_summary = pd.DataFrame({'offertime':offertimes_lst,\n",
    "                                           'mdm':mdm_dist_rank_expectations,\n",
    "                                           'rum':rum_dist_rank_expectations,\n",
    "                                           'mnl':mnl_dist_rank_expectations,\n",
    "                                           'mccm':mccm_dist_rank_expectations,\n",
    "                                           'lcmnl':lcmnl_dist_rank_expectations})\n",
    "expected_dist_rank_summary.to_csv('avg_ranking/expected_dist_rank_summary.csv')\n",
    "expected_dist_rank_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertime</th>\n",
       "      <th>mdm</th>\n",
       "      <th>rum</th>\n",
       "      <th>mnl</th>\n",
       "      <th>mccm</th>\n",
       "      <th>lcmnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2.92</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertime   mdm   rum   mnl  mccm  lcmnl\n",
       "0         20  2.87  3.15  3.10  2.89   2.99\n",
       "1         30  3.00  3.12  3.20  2.91   2.77\n",
       "2         40  2.76  3.24  3.44  2.91   2.65\n",
       "3         50  2.92  3.14  3.27  2.69   2.98\n",
       "4         60  2.96  2.91  3.06  3.01   3.06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the distribution of ranking of compared models\n",
    "\n",
    "\n",
    "mdm_regret_rank_realizations = []\n",
    "mdm_regret_rank_regretributions = []\n",
    "\n",
    "rum_regret_rank_realizations = []\n",
    "rum_regret_rank_regretributions = []\n",
    "\n",
    "mnl_regret_rank_realizations = []\n",
    "mnl_regret_rank_regretributions = []\n",
    "\n",
    "mccm_regret_rank_realizations = []\n",
    "mccm_regret_rank_regretributions = []\n",
    "\n",
    "lcmnl_regret_rank_realizations = []\n",
    "lcmnl_regret_rank_regretributions = []\n",
    "\n",
    "mdm_regret_rank_expectations = []\n",
    "rum_regret_rank_expectations = []\n",
    "mnl_regret_rank_expectations = []\n",
    "mccm_regret_rank_expectations = []\n",
    "lcmnl_regret_rank_expectations = []\n",
    "\n",
    "for i in range(len(offertimes_lst)):\n",
    "    mdm_realization, mdm_regretribution = get_distribution(all_mdm_regret_rank[i])\n",
    "    rum_realization, rum_regretribution = get_distribution(all_rum_regret_rank[i])\n",
    "    mnl_realization, mnl_regretribution = get_distribution(all_mnl_regret_rank[i])\n",
    "    mccm_realization, mccm_regretribution = get_distribution(all_mccm_regret_rank[i])\n",
    "    lcmnl_realization, lcmnl_regretribution = get_distribution(all_lcmnl_regret_rank[i])\n",
    "    \n",
    "    mdm_df = pd.DataFrame({'realizations':mdm_realization,'distribution':mdm_regretribution})\n",
    "    mdm_df.to_csv('avg_ranking/regret/'+str(offertimes_lst[i])+'/mdm.csv')\n",
    "    \n",
    "    rum_df = pd.DataFrame({'realizations':rum_realization,'distribution':rum_regretribution})\n",
    "    rum_df.to_csv('avg_ranking/regret/'+str(offertimes_lst[i])+'/rum.csv')\n",
    "    \n",
    "    mnl_df = pd.DataFrame({'realizations':mnl_realization,'distribution':mnl_regretribution})\n",
    "    mnl_df.to_csv('avg_ranking/regret/'+str(offertimes_lst[i])+'/mnl.csv')\n",
    "    \n",
    "    mccm_df = pd.DataFrame({'realizations':mccm_realization,'distribution':mccm_regretribution})\n",
    "    mccm_df.to_csv('avg_ranking/regret/'+str(offertimes_lst[i])+'/mccm.csv')\n",
    "    \n",
    "    lcmnl_df = pd.DataFrame({'realizations':lcmnl_realization,'distribution':lcmnl_regretribution})\n",
    "    lcmnl_df.to_csv('avg_ranking/regret/'+str(offertimes_lst[i])+'/lcmnl.csv')\n",
    "    \n",
    "    mdm_regret_rank_expectations.append(np.sum(mdm_realization * mdm_regretribution))\n",
    "    rum_regret_rank_expectations.append(np.sum(rum_realization * rum_regretribution))\n",
    "    mnl_regret_rank_expectations.append(np.sum(mnl_realization * mnl_regretribution))\n",
    "    mccm_regret_rank_expectations.append(np.sum(mccm_realization * mccm_regretribution))\n",
    "    lcmnl_regret_rank_expectations.append(np.sum(lcmnl_realization * lcmnl_regretribution))\n",
    "\n",
    "expected_regret_rank_summary = pd.DataFrame({'offertime':offertimes_lst,\n",
    "                                           'mdm':mdm_regret_rank_expectations,\n",
    "                                           'rum':rum_regret_rank_expectations,\n",
    "                                           'mnl':mnl_regret_rank_expectations,\n",
    "                                           'mccm':mccm_regret_rank_expectations,\n",
    "                                           'lcmnl':lcmnl_regret_rank_expectations})\n",
    "expected_regret_rank_summary.to_csv('avg_ranking/expected_regret_rank_summary.csv')\n",
    "expected_regret_rank_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.25       0.66666666 0.41666667]\n",
      "Expectation: 1.6666666700000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Given realizations and distribution\n",
    "realizations = np.array([1, 1.5, 2, 2.5])\n",
    "distribution = np.array([0.33333333, 0.16666667, 0.33333333, 0.16666667])\n",
    "print(realizations * distribution)\n",
    "# Calculate the expectation\n",
    "expectation = np.sum(realizations * distribution)\n",
    "print(\"Expectation:\", expectation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.5 2.  2.5] [0.33333333 0.16666667 0.33333333 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "data = [1, 1.5, 1, 2, 2.5, 2]\n",
    "\n",
    "# Get realizations and their distribution\n",
    "realizations, distribution = get_distribution(data)\n",
    "print(realizations, distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_w_models(distances):\n",
    "    # Sort the distances and assign ranks\n",
    "    sorted_distances = sorted(distances)\n",
    "    rank_list = []\n",
    "    rank = 1\n",
    "    previous_distance = sorted_distances[0]\n",
    "\n",
    "    # Assign ranks\n",
    "    for i, distance in enumerate(sorted_distances):\n",
    "        if distance > previous_distance:\n",
    "            rank = i + 1\n",
    "        rank_list.append(rank)\n",
    "        previous_distance = distance\n",
    "\n",
    "    # Reverse mapping the rank list to match the original distances order\n",
    "    final_rankings = [rank_list[sorted_distances.index(d)] for d in distances]\n",
    "\n",
    "    return final_rankings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_w_distance(distances):\n",
    "    # Combine distances with their original indices\n",
    "    indexed_distances = list(enumerate(distances))\n",
    "\n",
    "    # Sort based on distances\n",
    "    sorted_distances = sorted(indexed_distances, key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the ranking list\n",
    "    ranks = [0] * len(distances)\n",
    "\n",
    "    # Assign ranks\n",
    "    rank = 1\n",
    "    for i in range(len(sorted_distances)):\n",
    "        if i > 0 and sorted_distances[i][1] != sorted_distances[i-1][1]:\n",
    "            rank += 1\n",
    "        ranks[sorted_distances[i][0]] = rank\n",
    "\n",
    "    return ranks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_dist_w_tie(distances):\n",
    "    # Combine distances with their original indices\n",
    "    indexed_distances = list(enumerate(distances))\n",
    "\n",
    "    # Sort based on distances\n",
    "    sorted_distances = sorted(indexed_distances, key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the ranking list\n",
    "    ranks = [0] * len(distances)\n",
    "\n",
    "    # Assign ranks with averaging for ties\n",
    "    i = 0\n",
    "    while i < len(sorted_distances):\n",
    "        start = i\n",
    "        current_distance = sorted_distances[i][1]\n",
    "        \n",
    "        # Move forward to find the end of the tie\n",
    "        while i < len(sorted_distances) - 1 and sorted_distances[i + 1][1] == current_distance:\n",
    "            i += 1\n",
    "        \n",
    "        # Calculate the average rank for ties\n",
    "        average_rank = (start + 1 + i + 1) / 2.0\n",
    "        \n",
    "        # Assign the average rank to all tied elements\n",
    "        for j in range(start, i + 1):\n",
    "            ranks[sorted_distances[j][0]] = average_rank\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Kendall tau distances\n",
    "distances = [0, 1, 1, 3, 3]\n",
    "\n",
    "distance_rank = rank_w_distance(distances)\n",
    "model_rank = rank_w_models(distances)\n",
    "avg_rank = avg_dist_w_tie(distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
