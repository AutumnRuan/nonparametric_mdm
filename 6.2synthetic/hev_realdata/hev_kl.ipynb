{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "from random import choice\n",
    "import json\n",
    "import cvxpy as cp\n",
    "from tkinter import _flatten\n",
    "import copy\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import gumbel_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 9 different products\n",
      "there are 134 different assortments\n",
      "check offertimes 134\n"
     ]
    }
   ],
   "source": [
    "raw_jd_choice = pd.read_excel('data_processing/choices.xlsm')  \n",
    "jd_offertimes = raw_jd_choice.groupby('clickset')['clicknum'].sum()[raw_jd_choice.clickset.unique()]\n",
    "inc_prod_num = raw_jd_choice['clickset'].value_counts()[raw_jd_choice.clickset.unique()]\n",
    "assortment_info_df = pd.DataFrame({'assortments':raw_jd_choice.clickset.unique(),'offer_times':jd_offertimes,'includ_prod_num':inc_prod_num})\n",
    "\n",
    "# extended assortments with outside option \n",
    "# transfer to list\n",
    "clickset = raw_jd_choice['clickset']\n",
    "clickset_list = []\n",
    "for cset in clickset:\n",
    "    num_lst = json.loads(cset)\n",
    "    #clickset_list.append(num_lst+[0])\n",
    "    clickset_list.append([0]+num_lst)\n",
    "raw_jd_choice['clickset'] = clickset_list\n",
    "\n",
    "n = 9 # product size top 8 products and outside option\n",
    "print('there are {} different products'.format(n))\n",
    "jd_collection = []\n",
    "for cset in clickset_list:\n",
    "    if cset not in jd_collection:\n",
    "        jd_collection.append(cset)\n",
    "print('there are {} different assortments'.format(len(jd_collection)))\n",
    "print('check offertimes',len(jd_offertimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_distribution_hev(n,collection,price):\n",
    "    # generate mean \n",
    "    ''' mu_0 = np.random.uniform(2,3)\n",
    "    mu_1n = np.random.uniform(-3,-2,n-1) '''\n",
    "    # generate deterministic utilities for products\n",
    "    \n",
    "    rho = -0.5 # prices and utilities are negatively correlated\n",
    "    price_mean = np.mean(price[1:]) \n",
    "    price_std = np.std(price[1:])\n",
    "    \n",
    "    z = np.zeros(len(price[1:]))\n",
    "    for i in range(len(z)):\n",
    "        z[i] = (price[1:][i] - price_mean)/price_std\n",
    "        \n",
    "    mu_1n = np.zeros(len(z))\n",
    "    normal_rvs = np.random.randn(len(mu_1n))\n",
    "    for i in range(len(mu_1n)):\n",
    "        mu_1n[i] = rho*z[i] + np.sqrt(1-rho**2)*normal_rvs[i] \n",
    "    ## deterministic utility of the outside option is strictly greater than the utilities of the products\n",
    "    mu_0 = np.max(mu_1n) + 1\n",
    "    # np.random.uniform(-2,2,n-1)\n",
    "    mu = np.hstack((mu_0,mu_1n))\n",
    "    \n",
    "    scale_0 = 10\n",
    "    scale_1n = np.random.uniform(0.04,1,n-1)\n",
    "    scales = np.hstack((scale_0,scale_1n))\n",
    "    \n",
    "    sample_size = 10000\n",
    "    utility_samples = np.array([gumbel_r.rvs(loc=mu, scale=scales) for _ in range(sample_size)])\n",
    "    # generate covariance matrix with positive correlation\n",
    "    # neg_cov = generate_negatively_correlated_covariance_matrix(n)\n",
    "    # if is_positive_semidefinite(neg_cov): \n",
    "    #     sample_size = 10000\n",
    "    #     utility_samples = np.random.multivariate_normal(mu,neg_cov,size=sample_size)\n",
    "    # else:\n",
    "    #     print('Negative correlation matrix error')\n",
    "    \n",
    "    collection_distribution = np.zeros((n,len(collection)))\n",
    "    for i in range(len(collection)):\n",
    "        curr_assortment = collection[i]\n",
    "        curr_population = [[] for _ in range(sample_size)] \n",
    "\n",
    "        for j in range(sample_size):\n",
    "            for k in curr_assortment:\n",
    "                curr_population[j].append(utility_samples[j][k])\n",
    "                # each sub list records only the utilities of products in the current assortment\n",
    "                \n",
    "        frequency = [0]*len(curr_assortment)\n",
    "        for j in range(sample_size):\n",
    "            max_index = np.argmax(np.array(curr_population[j]))\n",
    "            # product is chosen iff the utility of the product is max in the assortment\n",
    "            frequency[max_index] = frequency[max_index] +1 \n",
    "            # update the frequency of product to be chosen\n",
    "            \n",
    "        prob = np.array(frequency)/np.sum(frequency)\n",
    "        for j in range(len(curr_assortment)):\n",
    "            collection_distribution[curr_assortment[j]][i] = prob[j]\n",
    "            \n",
    "    return collection_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_instance_generation(n,whole_collection,whole_offertimes,price):\n",
    "    ## generate LCMNL instances based on the assortment collection infomation\n",
    "    # step 1: randomly generate LCMNL parameters\n",
    "    # 1.1 the number of classes in LCMNL, the number of classes is between 10 and 15, both endpoints are included\n",
    "    ''' num_classes = 20\n",
    "    # 1.2 randomly generate weights of all classes \n",
    "    #weight_pre = np.random.exponential(1, num_classes)\n",
    "    weights = np.array([1/ num_classes for _ in range(num_classes)])\n",
    "    # 1.3 randomly generate parameters of each mnl\n",
    "    parameters_v = np.random.uniform(-30, 30, size=(num_classes,n)) '''\n",
    "    ''' parameters_v = np.zeros((num_classes,n))\n",
    "    for i in range(num_classes):\n",
    "        parameters_v[i] = np.random.exponential(1, n) '''\n",
    "    #np.random.uniform(-30, 30, size=(num_classes,n))\n",
    "    # step 2: generate LCMNL instance with the above parameters of LCMNL\n",
    "    true_hev_instance = collection_distribution_hev(n,whole_collection,price)\n",
    "    # step 3: generate multinomial samples based on lcmnl instance and the emprical assortment offertimes\n",
    "    purchased_samples = []\n",
    "    for i in range(len(whole_collection)):\n",
    "        sample_i = np.random.multinomial(whole_offertimes[i], true_hev_instance[:,i])\n",
    "        purchased_samples.append(sample_i)\n",
    "    # step 4: compute the simulated collection probabilities\n",
    "    whole_choice_collection = np.zeros((n,len(whole_collection)))\n",
    "    for i in range(len(whole_collection)):\n",
    "        whole_choice_collection[:,i] = np.array([k/np.sum(purchased_samples[i]) for k in purchased_samples[i]])\n",
    "        \n",
    "    return whole_choice_collection,purchased_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_collection_offertimes(whole_collection,whole_offertimes,least_offetimes):\n",
    "    \n",
    "    collection = []\n",
    "    offertimes = []\n",
    "    assortment_index = []\n",
    "    \n",
    "    for i in range(len(whole_offertimes)):\n",
    "        if whole_offertimes[i]>=least_offetimes:\n",
    "            collection.append(whole_collection[i])\n",
    "            offertimes.append(whole_offertimes[i])\n",
    "            assortment_index.append(i)\n",
    "            \n",
    "    return collection,offertimes,assortment_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_offer_times_list = [20,30,40,50,60]\n",
    "pred_test_collection_size = [5,4,3,3,2]\n",
    "pred_train_collection_size = [24,20,16,12,11]\n",
    "pred_instance_size = [50,50,50,50,50]\n",
    "price = np.array([0,1.041,0.456,0.391,1.657,1.174,0.474,0.67,1.522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of assortments with offertimes 20 is 29\n",
      "number of assortments with offertimes 30 is 24\n",
      "number of assortments with offertimes 40 is 19\n",
      "number of assortments with offertimes 50 is 15\n",
      "number of assortments with offertimes 60 is 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_full_collections = []\n",
    "all_full_offertimes = []\n",
    "all_full_assortment_index = []\n",
    "full_collection_size = []\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    collection, offertimes, assortment_index = filter_collection_offertimes(jd_collection,jd_offertimes,pred_offer_times_list[i])\n",
    "    all_full_collections.append(collection)\n",
    "    all_full_offertimes.append(offertimes)\n",
    "    all_full_assortment_index.append(assortment_index)\n",
    "    full_collection_size.append(len(assortment_index))\n",
    "    print(\"number of assortments with offertimes {} is {}\".format(pred_offer_times_list[i], len(assortment_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_probability_frequency2(whole_choice_collection,purchase_samples,assortment_index):\n",
    "    \n",
    "    choice_collection = np.zeros((whole_choice_collection.shape[0],len(assortment_index)))\n",
    "    frequency_collection = np.zeros((whole_choice_collection.shape[0],len(assortment_index)))\n",
    "    for i in range(len(assortment_index)):\n",
    "        choice_collection[:,i] = whole_choice_collection[:,assortment_index[i]]\n",
    "        frequency_collection[:,i] = purchase_samples[assortment_index[i]]\n",
    "        \n",
    "    return choice_collection,frequency_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 0 th instance\n",
      "generating 1 th instance\n",
      "generating 2 th instance\n",
      "generating 3 th instance\n",
      "generating 4 th instance\n",
      "generating 5 th instance\n",
      "generating 6 th instance\n",
      "generating 7 th instance\n",
      "generating 8 th instance\n",
      "generating 9 th instance\n",
      "generating 10 th instance\n",
      "generating 11 th instance\n",
      "generating 12 th instance\n",
      "generating 13 th instance\n",
      "generating 14 th instance\n",
      "generating 15 th instance\n",
      "generating 16 th instance\n",
      "generating 17 th instance\n",
      "generating 18 th instance\n",
      "generating 19 th instance\n",
      "generating 20 th instance\n",
      "generating 21 th instance\n",
      "generating 22 th instance\n",
      "generating 23 th instance\n",
      "generating 24 th instance\n",
      "generating 25 th instance\n",
      "generating 26 th instance\n",
      "generating 27 th instance\n",
      "generating 28 th instance\n",
      "generating 29 th instance\n",
      "generating 30 th instance\n",
      "generating 31 th instance\n",
      "generating 32 th instance\n",
      "generating 33 th instance\n",
      "generating 34 th instance\n",
      "generating 35 th instance\n",
      "generating 36 th instance\n",
      "generating 37 th instance\n",
      "generating 38 th instance\n",
      "generating 39 th instance\n",
      "generating 40 th instance\n",
      "generating 41 th instance\n",
      "generating 42 th instance\n",
      "generating 43 th instance\n",
      "generating 44 th instance\n",
      "generating 45 th instance\n",
      "generating 46 th instance\n",
      "generating 47 th instance\n",
      "generating 48 th instance\n",
      "generating 49 th instance\n"
     ]
    }
   ],
   "source": [
    "# generate instances that satisfy for assortment offertimes is >=20\n",
    "## generate 50 random full instances \n",
    "# the observations with at least 20 times are >= 1e-3\n",
    "pred_full_instance = []\n",
    "pred_full_samples = []\n",
    "#collection_20,offertimes_20,assortment_index = filter_collection_offertimes(jd_collection,jd_offertimes,pred_offer_times_list[0])\n",
    "\n",
    "for j in range(pred_instance_size[0]):\n",
    "    print(f'generating {j} th instance')\n",
    "    # full instance generation \n",
    "    curr_whole_instance,curr_purchase_samples = whole_instance_generation(n,jd_collection,jd_offertimes,price)\n",
    "    # filter choice probability and purchase frequency of each produt in each assortment\n",
    "    curr_choice_collection,curr_frequency = filter_probability_frequency2(curr_whole_instance,curr_purchase_samples,all_full_assortment_index[0])\n",
    "    \n",
    "    pred_full_instance.append(curr_whole_instance)\n",
    "    pred_full_samples.append(curr_purchase_samples)\n",
    "    #print(pd.DataFrame(curr_whole_instance))\n",
    "    \n",
    "    ''' condition = False\n",
    "    for x in range(len(all_full_collections[0])):\n",
    "        for y in all_full_collections[0][x]:\n",
    "            if curr_choice_collection[y][x]<1e-6 or curr_choice_collection[y][x] >0.999:\n",
    "                condition = True\n",
    "    while condition:\n",
    "        curr_whole_instance,curr_purchase_samples = whole_instance_generation(n,jd_collection,jd_offertimes,price)\n",
    "        # filter choice probability and purchase frequency of each produt in each assortment\n",
    "        curr_choice_collection,curr_frequency = filter_probability_frequency2(curr_whole_instance,curr_purchase_samples,all_full_assortment_index[0])\n",
    "\n",
    "        condition = False\n",
    "        for x in range(len(all_full_collections[0])):\n",
    "            for y in all_full_collections[0][x]:\n",
    "                if curr_choice_collection[y][x] < 1e-6 or curr_choice_collection[y][x] >0.999:\n",
    "                    condition = True\n",
    "    if condition == True:\n",
    "        print('instance_generation error')\n",
    "    else:  \n",
    "        pred_full_instance.append(curr_whole_instance)\n",
    "        pred_full_samples.append(curr_purchase_samples)    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lb_ub_w_ci(frequency_collection,choice_collection,target_z_score):\n",
    "    \n",
    "    stardard_error = np.zeros(frequency_collection.shape)\n",
    "    for i in range(stardard_error.shape[0]):\n",
    "        for j in range(stardard_error.shape[1]):\n",
    "            if frequency_collection[i][j]!=0:\n",
    "                stardard_error[i][j] = np.sqrt((1-choice_collection[i][j])/frequency_collection[i][j])\n",
    "                \n",
    "    lb = np.zeros(frequency_collection.shape)\n",
    "    ub = np.zeros(frequency_collection.shape)\n",
    "    for i in range(lb.shape[0]):\n",
    "        for j in range(lb.shape[1]):\n",
    "            if frequency_collection[i][j]!=0:\n",
    "                lb[i][j] = choice_collection[i][j] * (1-target_z_score*stardard_error[i][j]) \n",
    "                ub[i][j] = choice_collection[i][j] * (1+target_z_score*stardard_error[i][j])\n",
    "    \n",
    "    return lb,ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check assortment index for offertimes 20\n",
      "check assortment index for offertimes 30\n",
      "check assortment index for offertimes 40\n",
      "check assortment index for offertimes 50\n",
      "check assortment index for offertimes 60\n"
     ]
    }
   ],
   "source": [
    "# full instance generation \n",
    "all_full_instances = []\n",
    "all_full_lb = []\n",
    "all_full_ub = []\n",
    "\n",
    "# pre-determined confidence interval \n",
    "confidence_level = 0.995\n",
    "alpha = 1 - confidence_level\n",
    "# Find z-score for the given confidence level\n",
    "target_z_score = stats.norm.ppf(1 - alpha / 2)  \n",
    "\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    \n",
    "    full_instances = []\n",
    "    full_lbs = []\n",
    "    full_ubs = []\n",
    "    print(f'check assortment index for offertimes {pred_offer_times_list[i]}')\n",
    "    for j in range(pred_instance_size[i]):\n",
    "        # filter choice probability and purchase frequency of each produt in each assortment\n",
    "        curr_choice_collection,curr_frequency = filter_probability_frequency2(pred_full_instance[j],pred_full_samples[j],all_full_assortment_index[i])\n",
    "        # re-check if all choice probability are >= 1e-3\n",
    "        ''' condition = False\n",
    "        for x in range(len(all_full_collections[i])):\n",
    "            for y in all_full_collections[i][x]:\n",
    "                if curr_choice_collection[y][x] < 1e-3:\n",
    "                    condition = True\n",
    "        if condition == True:\n",
    "            print('instance_generation error') '''\n",
    "        \n",
    "        # compute the collection of lower bound and upper bound l_ij and u_ij\n",
    "        curr_lb,curr_ub = compute_lb_ub_w_ci(curr_frequency,curr_choice_collection,target_z_score)\n",
    "        \n",
    "        full_instances.append(curr_choice_collection)\n",
    "        full_lbs.append(curr_lb)\n",
    "        full_ubs.append(curr_ub)\n",
    "    \n",
    "    all_full_instances.append(full_instances)\n",
    "    all_full_lb.append(full_lbs)\n",
    "    all_full_ub.append(full_ubs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mdm_kl_loss = []\n",
    "all_mdm_avg_kl_loss = []\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    mdm_kl_loss_collection = []\n",
    "    mdm_avg_kl_loss_collection = []\n",
    "    for j in range(pred_instance_size[i]):\n",
    "        mdm_prob = pd.read_csv('limit/mdm/limit/limit_prob/offertimes'+str(pred_offer_times_list[i])+'/limit_prob_'+str(pred_offer_times_list[i])+'_'+str(j)+'.csv')\n",
    "        mdm_prob = mdm_prob.drop(mdm_prob.columns[0],axis=1)\n",
    "        mdm_prob = np.array(mdm_prob)\n",
    "        data = all_full_instances[i][j]\n",
    "        curr_kl_loss = 0\n",
    "        for x in range(data.shape[0]):\n",
    "            for y in range(data.shape[1]):\n",
    "                if data[x][y]>0 and mdm_prob[x][y]>0:\n",
    "                    curr_kl_loss = curr_kl_loss + all_full_offertimes[i][y]* data[x][y]*np.log(mdm_prob[x][y]/data[x][y])\n",
    "        mdm_kl_loss_collection.append(-curr_kl_loss)\n",
    "        mdm_avg_kl_loss_collection.append(-curr_kl_loss/sum(all_full_offertimes[i]))\n",
    "        \n",
    "    df_mdm_loss = pd.DataFrame({'ins_idx':list(range(pred_instance_size[i])),'mdm_loss':mdm_kl_loss_collection,'avg_loss':mdm_avg_kl_loss_collection})\n",
    "    df_mdm_loss.to_csv('limit/mdm/limit_kl/'+str(pred_offer_times_list[i])+'.csv')\n",
    "    \n",
    "    all_mdm_kl_loss.append(mdm_kl_loss_collection) \n",
    "    all_mdm_avg_kl_loss.append(mdm_avg_kl_loss_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertimes</th>\n",
       "      <th>total_mdm_kl_loss</th>\n",
       "      <th>total_mdm_kl_loss_se</th>\n",
       "      <th>avg_mdm_kl_loss</th>\n",
       "      <th>avg_mdm_kl_loss_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>28.610152</td>\n",
       "      <td>1.889440</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>21.744391</td>\n",
       "      <td>1.380442</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>15.772163</td>\n",
       "      <td>1.293798</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>9.614406</td>\n",
       "      <td>1.026123</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>8.836664</td>\n",
       "      <td>1.206013</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertimes  total_mdm_kl_loss  total_mdm_kl_loss_se  avg_mdm_kl_loss  \\\n",
       "0          20          28.610152              1.889440         0.003737   \n",
       "1          30          21.744391              1.380442         0.002888   \n",
       "2          40          15.772163              1.293798         0.002143   \n",
       "3          50           9.614406              1.026123         0.001337   \n",
       "4          60           8.836664              1.206013         0.001248   \n",
       "\n",
       "   avg_mdm_kl_loss_se  \n",
       "0            0.000247  \n",
       "1            0.000183  \n",
       "2            0.000176  \n",
       "3            0.000143  \n",
       "4            0.000170  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_total_kl_loss = []\n",
    "avg_total_kl_loss_se = []\n",
    "avg_avg_kl_loss = []\n",
    "avg_avg_kl_loss_se = []\n",
    "\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    avg_total_kl_loss.append(np.mean(all_mdm_kl_loss[i]))\n",
    "    avg_total_kl_loss_se.append(np.std(all_mdm_kl_loss[i])/np.sqrt(len(all_mdm_kl_loss[i])))\n",
    "    \n",
    "    avg_avg_kl_loss.append(np.mean(all_mdm_avg_kl_loss[i]))\n",
    "    avg_avg_kl_loss_se.append(np.std(all_mdm_avg_kl_loss[i])/np.sqrt(len(all_mdm_avg_kl_loss[i])))\n",
    "    \n",
    "df_mdm_kl = pd.DataFrame({'offertimes':pred_offer_times_list,\n",
    "                                   'total_mdm_kl_loss':avg_total_kl_loss,'total_mdm_kl_loss_se':avg_total_kl_loss_se,\n",
    "                                   'avg_mdm_kl_loss':avg_avg_kl_loss,'avg_mdm_kl_loss_se':avg_avg_kl_loss_se\n",
    "                                   })\n",
    "df_mdm_kl.to_csv('limit/mdm/mdm_kl_summary.csv')\n",
    "df_mdm_kl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rum_kl_loss = []\n",
    "all_rum_avg_kl_loss = []\n",
    "for i in range(len(pred_offer_times_list)): \n",
    "    rum_kl_loss_collection = []\n",
    "    rum_avg_kl_loss_collection = []\n",
    "    for j in range(pred_instance_size[i]):\n",
    "        #limit_prob = all_rum_limit_prob[i][j]\n",
    "        rum_prob = pd.read_csv('limit/rum/limit/limit_prob/offertimes'+str(pred_offer_times_list[i])+'/limit_prob_'+str(pred_offer_times_list[i])+'_'+str(j)+'.csv')\n",
    "        rum_prob = rum_prob.drop(rum_prob.columns[0],axis=1)\n",
    "        limit_prob = np.array(rum_prob)\n",
    "        \n",
    "        data = all_full_instances[i][j]\n",
    "        curr_kl_loss = 0\n",
    "        for x in range(data.shape[0]):\n",
    "            for y in range(data.shape[1]):\n",
    "                if data[x][y]>0 and limit_prob[x][y]>0:\n",
    "                    curr_kl_loss = curr_kl_loss + all_full_offertimes[i][y]*data[x][y]*np.log(limit_prob[x][y]/data[x][y])\n",
    "        rum_kl_loss_collection.append(-curr_kl_loss)\n",
    "        rum_avg_kl_loss_collection.append(-curr_kl_loss/sum(all_full_offertimes[i]))\n",
    "    df_rum_loss = pd.DataFrame({'ins_idx':list(range(pred_instance_size[i])),'rum_loss':rum_kl_loss_collection,'avg_loss':rum_avg_kl_loss_collection})\n",
    "    df_rum_loss.to_csv('limit/rum/limit_kl/'+str(pred_offer_times_list[i])+'.csv')\n",
    "    \n",
    "    all_rum_kl_loss.append(rum_kl_loss_collection) \n",
    "    all_rum_avg_kl_loss.append(rum_avg_kl_loss_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertimes</th>\n",
       "      <th>total_rum_kl_loss</th>\n",
       "      <th>total_rum_kl_loss_se</th>\n",
       "      <th>avg_rum_kl_loss</th>\n",
       "      <th>avg_rum_kl_loss_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>28.279343</td>\n",
       "      <td>1.394174</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>21.128118</td>\n",
       "      <td>1.408280</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>15.380584</td>\n",
       "      <td>1.244505</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>10.039310</td>\n",
       "      <td>1.080540</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>7.845557</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertimes  total_rum_kl_loss  total_rum_kl_loss_se  avg_rum_kl_loss  \\\n",
       "0          20          28.279343              1.394174         0.003694   \n",
       "1          30          21.128118              1.408280         0.002806   \n",
       "2          40          15.380584              1.244505         0.002089   \n",
       "3          50          10.039310              1.080540         0.001396   \n",
       "4          60           7.845557              0.997567         0.001108   \n",
       "\n",
       "   avg_rum_kl_loss_se  \n",
       "0            0.000182  \n",
       "1            0.000187  \n",
       "2            0.000169  \n",
       "3            0.000150  \n",
       "4            0.000141  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_total_kl_loss = []\n",
    "avg_total_kl_loss_se = []\n",
    "avg_avg_kl_loss = []\n",
    "avg_avg_kl_loss_se = []\n",
    "\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    avg_total_kl_loss.append(np.mean(all_rum_kl_loss[i]))\n",
    "    avg_total_kl_loss_se.append(np.std(all_rum_kl_loss[i])/np.sqrt(len(all_rum_kl_loss[i])))\n",
    "    \n",
    "    avg_avg_kl_loss.append(np.mean(all_rum_avg_kl_loss[i]))\n",
    "    avg_avg_kl_loss_se.append(np.std(all_rum_avg_kl_loss[i])/np.sqrt(len(all_rum_avg_kl_loss[i])))\n",
    "    \n",
    "df_rum_kl = pd.DataFrame({'offertimes':pred_offer_times_list,\n",
    "                                   'total_rum_kl_loss':avg_total_kl_loss,'total_rum_kl_loss_se':avg_total_kl_loss_se,\n",
    "                                   'avg_rum_kl_loss':avg_avg_kl_loss,'avg_rum_kl_loss_se':avg_avg_kl_loss_se\n",
    "                                   })\n",
    "df_rum_kl.to_csv('limit/rum/rum_kl_summary.csv')\n",
    "df_rum_kl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mnl_kl_loss = []\n",
    "all_mnl_avg_kl_loss = []\n",
    "for i in range(len(pred_offer_times_list)): \n",
    "    mnl_kl_loss_collection = []\n",
    "    mnl_avg_kl_loss_collection = []\n",
    "    for j in range(pred_instance_size[i]):\n",
    "        \n",
    "        mnl_prob = pd.read_csv('limit/mnl/limit/limit_prob/offertimes'+str(pred_offer_times_list[i])+'/limit_prob_'+str(pred_offer_times_list[i])+'_'+str(j)+'.csv')\n",
    "        mnl_prob = mnl_prob.drop(mnl_prob.columns[0],axis=1)\n",
    "        limit_prob = np.array(mnl_prob)\n",
    "        \n",
    "        #limit_prob = all_mnl_limit_prob[i][j]\n",
    "        data = all_full_instances[i][j]\n",
    "        curr_kl_loss = 0\n",
    "        for x in range(data.shape[0]):\n",
    "            for y in range(data.shape[1]):\n",
    "                if data[x][y]>0:\n",
    "                    curr_kl_loss = curr_kl_loss + all_full_offertimes[i][y]*data[x][y]*np.log(limit_prob[x][y]/data[x][y])\n",
    "        mnl_kl_loss_collection.append(-curr_kl_loss)\n",
    "        mnl_avg_kl_loss_collection.append(-curr_kl_loss/sum(all_full_offertimes[i]))\n",
    "    df_mnl_loss = pd.DataFrame({'ins_idx':list(range(pred_instance_size[i])),'mnl_loss':mnl_kl_loss_collection,'avg_loss':mnl_avg_kl_loss_collection})\n",
    "    df_mnl_loss.to_csv('limit/mnl/limit_kl/'+str(pred_offer_times_list[i])+'.csv')\n",
    "    \n",
    "    all_mnl_kl_loss.append(mnl_kl_loss_collection) \n",
    "    all_mnl_avg_kl_loss.append(mnl_avg_kl_loss_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertimes</th>\n",
       "      <th>total_mnl_kl_loss</th>\n",
       "      <th>total_mnl_kl_loss_se</th>\n",
       "      <th>avg_mnl_kl_loss</th>\n",
       "      <th>avg_mnl_kl_loss_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>148.757021</td>\n",
       "      <td>3.655840</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>130.229694</td>\n",
       "      <td>3.671666</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>109.435407</td>\n",
       "      <td>3.308701</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.000449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>88.610340</td>\n",
       "      <td>3.079184</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>75.923897</td>\n",
       "      <td>2.980402</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertimes  total_mnl_kl_loss  total_mnl_kl_loss_se  avg_mnl_kl_loss  \\\n",
       "0          20         148.757021              3.655840         0.019433   \n",
       "1          30         130.229694              3.671666         0.017297   \n",
       "2          40         109.435407              3.308701         0.014867   \n",
       "3          50          88.610340              3.079184         0.012324   \n",
       "4          60          75.923897              2.980402         0.010721   \n",
       "\n",
       "   avg_mnl_kl_loss_se  \n",
       "0            0.000478  \n",
       "1            0.000488  \n",
       "2            0.000449  \n",
       "3            0.000428  \n",
       "4            0.000421  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_total_kl_loss = []\n",
    "avg_total_kl_loss_se = []\n",
    "avg_avg_kl_loss = []\n",
    "avg_avg_kl_loss_se = []\n",
    "\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    avg_total_kl_loss.append(np.mean(all_mnl_kl_loss[i]))\n",
    "    avg_total_kl_loss_se.append(np.std(all_mnl_kl_loss[i])/np.sqrt(len(all_mnl_kl_loss[i])))\n",
    "    \n",
    "    avg_avg_kl_loss.append(np.mean(all_mnl_avg_kl_loss[i]))\n",
    "    avg_avg_kl_loss_se.append(np.std(all_mnl_avg_kl_loss[i])/np.sqrt(len(all_mnl_avg_kl_loss[i])))\n",
    "    \n",
    "df_mnl_kl = pd.DataFrame({'offertimes':pred_offer_times_list,\n",
    "                                   'total_mnl_kl_loss':avg_total_kl_loss,'total_mnl_kl_loss_se':avg_total_kl_loss_se,\n",
    "                                   'avg_mnl_kl_loss':avg_avg_kl_loss,'avg_mnl_kl_loss_se':avg_avg_kl_loss_se\n",
    "                                   })\n",
    "df_mnl_kl.to_csv('limit/mnl/mnl_kl_summary.csv')\n",
    "df_mnl_kl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertimes</th>\n",
       "      <th>total_lcmnl_kl_loss</th>\n",
       "      <th>total_lcmnl_kl_loss_se</th>\n",
       "      <th>avg_lcmnl_kl_loss</th>\n",
       "      <th>avg_lcmnl_kl_loss_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>10.204440</td>\n",
       "      <td>0.501781</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>6.224155</td>\n",
       "      <td>0.363629</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>4.151991</td>\n",
       "      <td>0.371206</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3.408609</td>\n",
       "      <td>1.208478</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>2.483311</td>\n",
       "      <td>0.870619</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertimes  total_lcmnl_kl_loss  total_lcmnl_kl_loss_se  avg_lcmnl_kl_loss  \\\n",
       "0          20            10.204440                0.501781           0.001333   \n",
       "1          30             6.224155                0.363629           0.000827   \n",
       "2          40             4.151991                0.371206           0.000564   \n",
       "3          50             3.408609                1.208478           0.000474   \n",
       "4          60             2.483311                0.870619           0.000351   \n",
       "\n",
       "   avg_lcmnl_kl_loss_se  \n",
       "0              0.000066  \n",
       "1              0.000048  \n",
       "2              0.000050  \n",
       "3              0.000168  \n",
       "4              0.000123  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lcmnl_kl_loss = []\n",
    "all_lcmnl_avg_kl_loss = []\n",
    "for i in range(len(pred_offer_times_list)): \n",
    "    lcmnl_kl_loss_collection = []\n",
    "    lcmnl_avg_kl_loss_collection = []\n",
    "    for j in range(pred_instance_size[i]):\n",
    "        \n",
    "        lcmnl_prob = pd.read_csv('limit/lcmnl/limit/limit_prob/offertimes'+str(pred_offer_times_list[i])+'/limit_prob_'+str(pred_offer_times_list[i])+'_'+str(j)+'.csv')\n",
    "        lcmnl_prob = lcmnl_prob.drop(lcmnl_prob.columns[0],axis=1)\n",
    "        limit_prob = np.array(lcmnl_prob)\n",
    "        \n",
    "        #limit_prob = all_lcmnl_limit_prob[i][j]\n",
    "        data = all_full_instances[i][j]\n",
    "        curr_kl_loss = 0\n",
    "        for x in range(data.shape[0]):\n",
    "            for y in range(data.shape[1]):\n",
    "                if data[x][y]>0:\n",
    "                    curr_kl_loss = curr_kl_loss + all_full_offertimes[i][y]*data[x][y]*np.log(limit_prob[x][y]/data[x][y])\n",
    "        lcmnl_kl_loss_collection.append(-curr_kl_loss)\n",
    "        lcmnl_avg_kl_loss_collection.append(-curr_kl_loss/sum(all_full_offertimes[i]))\n",
    "    df_lcmnl_loss = pd.DataFrame({'ins_idx':list(range(pred_instance_size[i])),'lcmnl_loss':lcmnl_kl_loss_collection,'avg_loss':lcmnl_avg_kl_loss_collection})\n",
    "    df_lcmnl_loss.to_csv('limit/lcmnl/limit_kl/'+str(pred_offer_times_list[i])+'.csv')\n",
    "    \n",
    "    all_lcmnl_kl_loss.append(lcmnl_kl_loss_collection) \n",
    "    all_lcmnl_avg_kl_loss.append(lcmnl_avg_kl_loss_collection)\n",
    "\n",
    "avg_total_kl_loss = []\n",
    "avg_total_kl_loss_se = []\n",
    "avg_avg_kl_loss = []\n",
    "avg_avg_kl_loss_se = []\n",
    "\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    avg_total_kl_loss.append(np.mean(all_lcmnl_kl_loss[i]))\n",
    "    avg_total_kl_loss_se.append(np.std(all_lcmnl_kl_loss[i])/np.sqrt(len(all_lcmnl_kl_loss[i])))\n",
    "    \n",
    "    avg_avg_kl_loss.append(np.mean(all_lcmnl_avg_kl_loss[i]))\n",
    "    avg_avg_kl_loss_se.append(np.std(all_lcmnl_avg_kl_loss[i])/np.sqrt(len(all_lcmnl_avg_kl_loss[i])))\n",
    "    \n",
    "df_lcmnl_kl = pd.DataFrame({'offertimes':pred_offer_times_list,\n",
    "                                   'total_lcmnl_kl_loss':avg_total_kl_loss,'total_lcmnl_kl_loss_se':avg_total_kl_loss_se,\n",
    "                                   'avg_lcmnl_kl_loss':avg_avg_kl_loss,'avg_lcmnl_kl_loss_se':avg_avg_kl_loss_se\n",
    "                                   })\n",
    "df_lcmnl_kl.to_csv('limit/lcmnl/lcmnl_kl_summary.csv')\n",
    "df_lcmnl_kl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertimes</th>\n",
       "      <th>total_mem_kl_loss</th>\n",
       "      <th>total_mem_kl_loss_se</th>\n",
       "      <th>avg_mem_kl_loss</th>\n",
       "      <th>avg_mem_kl_loss_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>42.942942</td>\n",
       "      <td>1.503889</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>35.011245</td>\n",
       "      <td>1.504301</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>26.476379</td>\n",
       "      <td>1.299837</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>19.189205</td>\n",
       "      <td>1.209628</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>15.250160</td>\n",
       "      <td>1.070784</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertimes  total_mem_kl_loss  total_mem_kl_loss_se  avg_mem_kl_loss  \\\n",
       "0          20          42.942942              1.503889         0.005610   \n",
       "1          30          35.011245              1.504301         0.004650   \n",
       "2          40          26.476379              1.299837         0.003597   \n",
       "3          50          19.189205              1.209628         0.002669   \n",
       "4          60          15.250160              1.070784         0.002153   \n",
       "\n",
       "   avg_mem_kl_loss_se  \n",
       "0            0.000196  \n",
       "1            0.000200  \n",
       "2            0.000177  \n",
       "3            0.000168  \n",
       "4            0.000151  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mem_kl_loss = []\n",
    "all_mem_avg_kl_loss = []\n",
    "for i in range(len(pred_offer_times_list)): \n",
    "    mem_kl_loss_collection = []\n",
    "    mem_avg_kl_loss_collection = []\n",
    "    for j in range(pred_instance_size[i]):\n",
    "        \n",
    "        mem_prob = pd.read_csv('limit/mem/limit/limit_prob/offertimes'+str(pred_offer_times_list[i])+'/limit_prob_'+str(pred_offer_times_list[i])+'_'+str(j)+'.csv')\n",
    "        mem_prob = mem_prob.drop(mem_prob.columns[0],axis=1)\n",
    "        limit_prob = np.array(mem_prob)\n",
    "        \n",
    "        #limit_prob = all_mem_limit_prob[i][j]\n",
    "        data = all_full_instances[i][j]\n",
    "        curr_kl_loss = 0\n",
    "        for x in range(data.shape[0]):\n",
    "            for y in range(data.shape[1]):\n",
    "                if data[x][y]>0:\n",
    "                    curr_kl_loss = curr_kl_loss + all_full_offertimes[i][y]*data[x][y]*np.log(limit_prob[x][y]/data[x][y])\n",
    "        mem_kl_loss_collection.append(-curr_kl_loss)\n",
    "        mem_avg_kl_loss_collection.append(-curr_kl_loss/sum(all_full_offertimes[i]))\n",
    "    df_mem_loss = pd.DataFrame({'ins_idx':list(range(pred_instance_size[i])),'mem_loss':mem_kl_loss_collection,'avg_loss':mem_avg_kl_loss_collection})\n",
    "    df_mem_loss.to_csv('limit/mem/limit_kl/'+str(pred_offer_times_list[i])+'.csv')\n",
    "    \n",
    "    all_mem_kl_loss.append(mem_kl_loss_collection) \n",
    "    all_mem_avg_kl_loss.append(mem_avg_kl_loss_collection)\n",
    "\n",
    "avg_total_kl_loss = []\n",
    "avg_total_kl_loss_se = []\n",
    "avg_avg_kl_loss = []\n",
    "avg_avg_kl_loss_se = []\n",
    "\n",
    "for i in range(len(pred_offer_times_list)):\n",
    "    avg_total_kl_loss.append(np.mean(all_mem_kl_loss[i]))\n",
    "    avg_total_kl_loss_se.append(np.std(all_mem_kl_loss[i])/np.sqrt(len(all_mem_kl_loss[i])))\n",
    "    \n",
    "    avg_avg_kl_loss.append(np.mean(all_mem_avg_kl_loss[i]))\n",
    "    avg_avg_kl_loss_se.append(np.std(all_mem_avg_kl_loss[i])/np.sqrt(len(all_mem_avg_kl_loss[i])))\n",
    "    \n",
    "df_mem_kl = pd.DataFrame({'offertimes':pred_offer_times_list,\n",
    "                                   'total_mem_kl_loss':avg_total_kl_loss,'total_mem_kl_loss_se':avg_total_kl_loss_se,\n",
    "                                   'avg_mem_kl_loss':avg_avg_kl_loss,'avg_mem_kl_loss_se':avg_avg_kl_loss_se\n",
    "                                   })\n",
    "df_mem_kl.to_csv('limit/mem/mem_kl_summary.csv')\n",
    "df_mem_kl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offertimes</th>\n",
       "      <th>avg_mdm_kl_loss</th>\n",
       "      <th>avg_rum_kl_loss</th>\n",
       "      <th>avg_lcmnl_kl_loss</th>\n",
       "      <th>avg_mnl_kl_loss</th>\n",
       "      <th>avg_mem_kl_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.005610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>0.004650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.002669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>0.002153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offertimes  avg_mdm_kl_loss  avg_rum_kl_loss  avg_lcmnl_kl_loss  \\\n",
       "0          20         0.003737         0.003694           0.001333   \n",
       "1          30         0.002888         0.002806           0.000827   \n",
       "2          40         0.002143         0.002089           0.000564   \n",
       "3          50         0.001337         0.001396           0.000474   \n",
       "4          60         0.001248         0.001108           0.000351   \n",
       "\n",
       "   avg_mnl_kl_loss  avg_mem_kl_loss  \n",
       "0         0.019433         0.005610  \n",
       "1         0.017297         0.004650  \n",
       "2         0.014867         0.003597  \n",
       "3         0.012324         0.002669  \n",
       "4         0.010721         0.002153  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_kl = pd.concat([ df_mdm_kl['offertimes'],df_mdm_kl['avg_mdm_kl_loss'],df_rum_kl['avg_rum_kl_loss'],\n",
    "                    df_lcmnl_kl['avg_lcmnl_kl_loss'],df_mnl_kl['avg_mnl_kl_loss'],df_mem_kl['avg_mem_kl_loss']], axis=1)\n",
    "avg_kl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
